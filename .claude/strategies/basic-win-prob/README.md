# 作戦: 王道 (Royal Road)

**ID**: `basic-win-prob`
**バージョン**: 1.0.0
**ステータス**: ✅ 訓練完了（2025-11-20）

## 概要

最もシンプルで理解しやすい3連単予想アプローチ。

LightGBMを使って各馬の**1着確率を予測**し、確率が高い上位3頭を組み合わせて3連単を構築する。

## 仮説

- 過去の成績データから未来の成績を予測できる
- 馬・騎手・調教師の累積統計が有効な特徴量
- 馬場状態や距離などのレース条件が結果に影響する
- 人気（オッズ）情報は予測精度を向上させる

## アルゴリズム

### モデル

#### 1. オッズなしモデル
**用途**: レース前の事前予想

**特徴量**:
- 馬の累積成績（勝率、複勝率、平均着順、休養日数）
- 騎手の累積成績（勝率、複勝率）
- 調教師の累積成績（勝率、複勝率）
- レース条件（馬場状態、距離カテゴリ）
- 枠番、馬番

#### 2. オッズありモデル
**用途**: オッズ発表後の最終予想

**特徴量**:
- 上記すべて + 人気順位

### 予想方法

```
1. 各馬の1着確率を予測
   horse_1: 0.25
   horse_2: 0.18
   horse_3: 0.15
   horse_4: 0.12
   ...

2. 上位3頭を選択
   1着候補: horse_1 (25%)
   2着候補: horse_2 (18%)
   3着候補: horse_3 (15%)

3. 3連単を構築
   推奨: 1-2-3
```

## 実装

- 特徴量生成: `analysis/feature_engineering_v2.py`
- モデル訓練: `analysis/train_lightgbm.py`
- 使用テーブル:
  - stat_horse_cumulative
  - stat_jockey_cumulative
  - stat_trainer_cumulative

## 実行方法

```bash
# 1. 特徴量生成（既に実行済み）
cd backend
uv run python ../analysis/feature_engineering_v2.py

# 2. モデル訓練（GPU環境推奨）
uv run python ../analysis/train_lightgbm.py
```

## リスク・課題

### 1. クラス不均衡（重要度: 高）
- 8頭立てなら1着は1/8 = 12.5%
- 正例が極端に少ない
- **対策**: クラス重み付け、SMOTE検討

### 2. 3連単の組み合わせ爆発
- 上位3頭を固定すると柔軟性に欠ける
- **対策**: 上位N頭から複数パターン生成

### 3. 配当を考慮していない
- 的中率が高くても配当が低ければ収益は出ない
- **対策**: 期待値ベースの選択に移行

## 改善案

1. **ランク学習への移行**
   - LambdaMART、LambdaRankを使用
   - 順位を直接予測する

2. **アンサンブル学習**
   - 複数モデルの予測を組み合わせ
   - 馬特化、騎手特化、条件特化など

3. **期待値最適化**
   - 配当を考慮した選択
   - オッズと予測確率のギャップを利用

## 訓練結果（2025-11-20）

### モデル性能（5-fold CV平均）

#### オッズなしモデル
- ROC-AUC: **72.79%** (±2.21%)
- Accuracy: 88.53% (±0.19%)
- Recall: 0.68% (±0.26%) ⚠️ **要改善**
- F1 Score: 1.34% (±0.51%)

#### オッズありモデル
- ROC-AUC: **84.03%** (±1.16%) ✓ **優秀**
- Accuracy: 89.09% (±0.15%)
- Recall: 23.77% (±4.46%) ✓ **実用的**
- F1 Score: 33.04% (±4.42%)

### 主な発見

1. **オッズ情報の効果は絶大**
   - ROC-AUC: 72.79% → 84.03% (+11.24pt)
   - Recall: 0.68% → 23.77% (35倍改善)

2. **クラス不均衡の影響**
   - 1着は全体の11.32%のみ
   - オッズなしモデルのRecallが極端に低い

3. **実用性の評価**
   - オッズありモデルは実戦投入可能なレベル
   - 約4レースに1回、1着馬を捕捉

### 生成ファイル
- `analysis/output/models/lightgbm_no_odds.pkl` (258KB)
- `analysis/output/models/lightgbm_with_odds.pkl` (284KB)
- `analysis/output/models/training_report_20251120.md` - 詳細レポート
- `analysis/output/models/model_comparison.csv` - 性能比較表
- `analysis/output/models/feature_importance_*.png/csv` - 特徴量重要度

## バックテスト結果（2025-11-20）

### 実戦性能（2024年4月〜2025年11月、1,508レース）

| モデル | 的中率 | ROI | 収支 |
|--------|--------|-----|------|
| オッズなし | 2.59% | 16.89% | **-83%損失** |
| オッズあり | 5.24% | 26.95% | **-73%損失** |

### 🚨 重大な発見：人気依存の問題

**決定的な事実**:
- 1着予想の平均人気: **1.01位**（ほぼ常に1番人気）
- 1番人気を選ぶ確率: **99.27%**
- popularity特徴量の重要度: **79,293**（2位の11.4倍）
- 平均配当: 514円（人気馬の組み合わせ）

**結論**: モデルは独自判断をしておらず、オッズ（群衆の予想）をコピーしているだけ。

### 評価

✅ **技術的には成功**
- ROC-AUC 84.03%は優秀
- 1着的中率 49.73%
- モデル構築の手法は正しい

❌ **実戦では失敗**
- 人気馬偏重で低配当
- 期待値がマイナス
- 独自の「エッジ」がゼロ

### 生成ファイル
- `analysis/backtest.py` - バックテストスクリプト
- `analysis/analyze_predictions.py` - 相関分析スクリプト
- `analysis/output/backtest/backtest_analysis_20251120.md` - 詳細分析
- `analysis/output/backtest/backtest_*_20251120.csv` - 全レース結果
- `analysis/output/backtest/backtest_summary_*.txt` - サマリー

## 次のステップ

- [x] GPU環境で訓練実行（2025-11-20完了）
- [x] 性能評価（Accuracy, ROC-AUC, etc.）（2025-11-20完了）
- [x] バックテスト（過去データで検証）（2025-11-20完了）
- [x] 3連単構築ロジック実装（2025-11-20完了）
- [ ] 人気依存問題の解決（期待値ベース購入等）
- [ ] クラス重み付けによる再訓練（人気薄を選ぶように）
- [ ] 作戦２以降の開発（新しいアプローチ）
- [ ] API実装（全作戦完了後）

## 教訓

**学んだこと**:
1. ROC-AUCが高い ≠ 儲かる
2. 人気（オッズ）を特徴量に使うと、それに支配される
3. 期待値 = 的中率 × 配当 の最適化が重要
4. 独自の「エッジ」がなければ価値がない

**推奨**: 作戦１の改善よりも、新しい作戦（作戦２以降）に進むべき。

---

**作成日**: 2025-11-15
**最終更新**: 2025-11-20（バックテスト完了）
