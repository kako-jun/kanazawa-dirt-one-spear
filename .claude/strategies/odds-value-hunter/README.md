# 作戦: 穴馬ハンター (Odds Value Hunter)

**ID**: `odds-value-hunter`
**バージョン**: 1.0.0
**ステータス**: 計画中
**優先度**: 高

## 概要

**オッズと実力の乖離**を突いて高配当を狙う作戦。

AIの客観的な予測と、人間の集合知（オッズ）を比較し、過小評価されている馬（バリューホース）を発見する。的中率より**回収率重視**のアプローチ。

## 仮説

- **人間の予想にはバイアスがある**: 知名度、前回の成績などに引きずられる
- **AIは客観的**: 統計データのみで判断し、バイアスを避けられる
- **期待値が正なら長期的に勝てる**: 的中率が低くても配当が高ければ利益が出る
- **大穴を狙う**: 3連単は高配当を狙える馬券種

## 王道（basic-win-prob）との違い

| 観点 | basic-win-prob | odds-value-hunter |
|------|----------------|-------------------|
| 目標 | 的中率を上げる | 回収率を上げる |
| オッズ利用 | 予測精度向上のため使う | バイアス検出のため比較する |
| 馬券選択 | 勝率が高い馬 | 期待値が高い馬 |
| リスク | 低配当で収益が出ない | 的中率が低い |
| 哲学 | 安定志向 | ハイリスク・ハイリターン |

## アルゴリズム

### 1. 勝率予測（オッズ不使用）

AIが客観的に各馬の勝率を予測する。

```python
# オッズを使わずに予測
model = LightGBM(features=[
    'horse_cumulative_stats',
    'jockey_cumulative_stats',
    'trainer_cumulative_stats',
    'race_conditions',
    # NOTE: オッズは使わない！
])

predicted_probs = model.predict(race_data)
# 例: [0.25, 0.18, 0.12, 0.10, ...]
```

### 2. オッズから暗黙の勝率を逆算

人間の予想（オッズ）が示唆する勝率を計算する。

```python
# オッズから勝率を逆算
odds = [3.0, 5.5, 10.0, 12.0, ...]
odds_implied_prob = [1/o for o in odds]
# 例: [0.33, 0.18, 0.10, 0.08, ...]
```

### 3. 乖離率を計算

AI予測とオッズ勝率の差を計算する。

```python
bias_rate = (predicted_probs - odds_implied_prob) / odds_implied_prob
# 例: horse_A: -24%（過大評価）
#     horse_B: 0%（適正）
#     horse_C: +20%（過小評価！）
```

### 4. 期待値を計算

```python
ev = predicted_probs * payout - cost
# 例: horse_C: 0.12 × 1000円 - 100円 = +20円（期待値プラス！）
```

### 5. 期待値が正の馬券を選択

```
期待値が正の馬の組み合わせで3連単を構築:
- 1着: horse_C（大穴）
- 2着: horse_B（中穴）
- 3着: horse_D（中穴）
```

## 実装

### スクリプト

1. **`analysis/odds_value_hunter/calculate_ev.py`**
   - 期待値計算ロジック
   - オッズ勝率の逆算

2. **`analysis/odds_value_hunter/detect_bias.py`**
   - オッズバイアス検出
   - 過小評価馬のリストアップ

3. **`analysis/odds_value_hunter/backtest_ev.py`**
   - 期待値戦略のバックテスト
   - 回収率の測定

4. **`analysis/odds_value_hunter/predict_value_bet.py`**
   - 本番用の期待値ベース予想
   - 複数パターンの馬券生成

### 使用テーブル

- stat_horse_cumulative
- stat_jockey_cumulative
- stat_trainer_cumulative
- stat_odds_range（オッズ帯別成績）
- payouts（配当データ）

## 評価指標

### 回収率（最重要）
```
回収率 = (獲得配当の合計) / (購入金額の合計) × 100%
目標: 120%以上
```

### 的中率
```
的中率 = (的中回数) / (購入回数) × 100%
目標: 3%以上（低くてもOK）
```

### 平均配当
```
平均配当 = (獲得配当の合計) / (的中回数)
目標: 10,000円以上
```

### 期待値の正確性
```
実際の回収率と理論期待値の差
目標: ±10%以内
```

## リスク・課題

### 1. 的中率が低い（重要度: 高）
- 大穴狙いのため、外れが多い
- **対策**: 期待値が正の馬券のみ購入、確率閾値を設定

### 2. オッズの変動（重要度: 中）
- 最終確定前にオッズが変わる
- **対策**: オッズ確定直前に予想を更新

### 3. AI予測が外れた場合の損失（重要度: 中）
- 大穴外しは痛い
- **対策**: 複数パターンの馬券でリスク分散

### 4. バリューホースが存在しない可能性（重要度: 高）
- オッズが効率的市場なら乖離は少ない
- **対策**: 過去データで検証、本当にバイアスがあるか確認

## 改善案

1. **Kelly基準による賭け金最適化**
   - 期待値に応じて購入金額を調整
   - リスクとリターンのバランス

2. **複数レースのポートフォリオ最適化**
   - 1レースだけでなく、1日分のレースで最適化
   - リスク分散

3. **オッズ変動予測**
   - 発表直後と確定直前のオッズ変動パターンを学習
   - 最終オッズを予測して期待値を再計算

## バックテスト計画

### 検証項目
1. **バイアスの存在確認**
   - 過去のオッズと結果を比較
   - 本当に過小評価馬が存在するか？

2. **回収率の測定**
   - 期待値戦略で実際に利益が出るか？
   - 目標: 回収率120%以上

3. **最適な閾値探索**
   - 期待値がいくら以上なら購入すべきか？
   - リスク許容度の設定

### 実験設計

```python
# 時系列交差検証
for year in [2020, 2021, 2022, 2023]:
    train_data = data[data['year'] < year]
    test_data = data[data['year'] == year]

    # モデル訓練（オッズなし）
    model.fit(train_data)

    # 期待値計算
    ev = calculate_ev(model, test_data)

    # 馬券購入シミュレーション
    results = simulate_betting(ev, threshold=0)

    # 回収率測定
    recovery_rate = sum(results['payout']) / sum(results['cost'])
    print(f"{year}: {recovery_rate:.1%}")
```

## 次のステップ

- [ ] 過去データでオッズバイアスの存在を検証
- [ ] 期待値計算スクリプト実装
- [ ] バックテストで回収率を測定
- [ ] basic-win-probとの比較
- [ ] Kelly基準の導入検討

---

**作成日**: 2025-11-16
**最終更新**: 2025-11-16
