# 予想システム設計

金沢ダート一本槍の予想手法に関する包括的ドキュメント

---

## 目次

1. [オッズと人間のバイアスに関する考察](#1-オッズと人間のバイアスに関する考察)
2. [2つの予想ルート](#2-2つの予想ルート)
3. [時系列検証戦略](#3-時系列検証戦略)

---

## 1. オッズと人間のバイアスに関する考察

### 核心的な問いかけ

**オッズは人間の行動で決まるものであり、みんなの思い込みでありバイアスである。**

これを予想に組み込むのと、まったく考慮しないのとで比較すると面白い実験ができる。

### 実験的アプローチ

#### パターンA: オッズ完全無視型AI
- **特徴**: 純粋に馬の能力・過去成績・血統・騎手・馬場状態などの客観的データのみで予想
- **哲学**: 大穴の馬だろうと、オッズを事前に見なければAIは「大穴」と思わない
- **メリット**:
  - 人間の集団心理バイアスに影響されない
  - 過小評価されている馬を発見できる可能性
  - 「AIの独自判断」が明確
- **デメリット**:
  - 人間の知恵（オッズに反映される情報）を捨てている
  - 回収率が低くなる可能性

#### パターンB: オッズ考慮型AI
- **特徴**: 客観的データ + オッズ（人間の集合知）を特徴量として組み込む
- **哲学**: 人間の予想には何らかの合理性がある
- **メリット**:
  - 人間の集合知を活用できる
  - 回収率向上の可能性
  - 「人気薄の中から有望馬を選ぶ」という戦略が可能
- **デメリット**:
  - 人間のバイアスに引きずられる可能性
  - AIの独自性が薄れる

#### パターンC: ハイブリッド型
- **特徴**: 両方のモデルを構築し、予想を比較
- **実装例**:
  1. モデルA（オッズ無視）で予想
  2. モデルB（オッズ考慮）で予想
  3. 両者の差分を分析
  4. 最終的な投資判断は「AIと人間の予想が乖離している馬」を狙う

### 評価指標

両モデルを以下の指標で比較:
1. **的中率**: どちらが3連単を当てるか
2. **回収率**: どちらが儲かるか
3. **予想の独自性**: オッズとの相関係数
4. **大穴発見率**: 人気薄（オッズ高）の馬を的中させた回数

### 金沢ダート一本槍への適用

#### フェーズ1: 両モデルの構築
- モデルA: `predictor_no_odds.py` - オッズ除外
- モデルB: `predictor_with_odds.py` - オッズ含む

#### フェーズ2: 比較実験
- 過去データで両モデルの性能を比較
- 的中率・回収率・独自性を可視化

#### フェーズ3: 本番運用
- **戦略案1**: 両モデルが一致した時だけ購入（確信度重視）
- **戦略案2**: 両モデルが乖離した時だけ購入（大穴狙い）
- **戦略案3**: 回収率の高い方を採用

### 哲学的含意

#### AIは「大穴」を知らない

オッズを見ないAIにとって、全ての馬は「客観的データから見た確率」でしかない。

例:
- 人間: 「この馬はオッズ50倍の大穴だ」
- AI（オッズ無視）: 「この馬の勝率は客観的に15%と予想する」
→ もし的中すれば、5000円が75,000円に！

#### 「みんなが見落としている馬」を発見できるか？

人間の集団心理には以下のバイアスがある:
- **人気騎手バイアス**: 有名騎手を過大評価
- **前走バイアス**: 直近1走の結果に引きずられる
- **血統ブランドバイアス**: 有名種牡馬を過信
- **馬体重バイアス**: 増減に過剰反応

AIは冷静にこれらを統計的に評価できる。

### データ保存戦略

#### オッズデータの取得時期

現在の実装: `odds: null`

理由:
- レース前のオッズは時間と共に変動
- 確定オッズ（発走直前）が最も重要

**今後の方針**:
1. 確定オッズを結果と一緒に取得
2. YAMLに `final_odds` フィールドを追加
3. 実験用に両モデルを構築

---

## 2. 2つの予想ルート

予想システムは**2つの独立したルート**で開発し、最終的に比較・統合する。

### ルートA: 解釈可能な機械学習（ホワイトボックス）
- 各特徴量の重みを調整
- **なぜその予想になったか説明できる**
- LightGBM、ロジスティック回帰など

### ルートB: ディープラーニング（ブラックボックス）
- 大量データを与えて学習
- **説明不可能だが高精度の可能性**
- ニューラルネットワーク、Transformer

---

## 2.1 ルートA: 解釈可能な機械学習

### 基本的な流れ

```
[1] 特徴量エンジニアリング
  各観点（枠番、オッズ、前走成績など）を数値化
  ↓
[2] モデル学習
  LightGBMなどで各特徴量の重みを自動学習
  ↓
[3] 重み調整（ハイパーパラメータチューニング）
  精度が最大になるように重みを探索
  ↓
[4] 予想生成
  各馬にスコアを付け、上位3頭を3連単として出力
  ↓
[5] 説明可能性の確保
  SHAP値で「なぜこの馬を選んだか」を説明
```

### 特徴量の例（観点）

各観点を数値化してモデルに入力:

```python
# 特徴量の例
features = {
    # 基本情報
    "gate_number": 3,              # 枠番
    "horse_number": 5,             # 馬番
    "odds": 4.2,                   # オッズ
    "popularity": 2,               # 人気順

    # 馬の情報
    "horse_age": 4,                # 馬齢
    "horse_weight": 485,           # 馬体重
    "weight_change": -3,           # 前走からの体重変化

    # 過去成績
    "last_1_rank": 2,              # 前走着順
    "last_3_avg_rank": 3.3,        # 過去3走平均着順
    "win_rate": 0.18,              # 通算勝率
    "place_rate": 0.45,            # 通算連対率

    # 騎手情報
    "jockey_win_rate": 0.22,       # 騎手勝率
    "jockey_experience": 1234,     # 騎手の騎乗回数

    # レース条件
    "distance": 1500,              # 距離
    "track_condition": 1,          # 馬場状態（良=1, 稍重=2...）
    "weather": 1,                  # 天候（晴=1, 曇=2...）

    # 相性
    "distance_win_rate": 0.21,     # この距離での勝率
    "track_condition_win_rate": 0.19,  # この馬場での勝率

    # 休養
    "days_since_last_race": 21,    # 前走からの日数
    "is_rest_comeback": 0,         # 休養明けフラグ

    # 調子
    "recent_trend": 0.15,          # 過去5走の成績トレンド（上昇=正）
}
```

### モデルの学習（LightGBM Ranker）

```python
import lightgbm as lgb

# データ準備
train_data = lgb.Dataset(
    X_train,  # 特徴量行列
    label=y_train,  # ラベル（1着=1, 2着=2, ...）
    group=groups_train  # レースごとのグルーピング
)

# ハイパーパラメータ
params = {
    'objective': 'lambdarank',  # ランキング学習
    'metric': 'ndcg',  # 評価指標
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
}

# 学習
model = lgb.train(params, train_data, num_boost_round=100)

# 特徴量重要度を取得
importance = model.feature_importance(importance_type='gain')
```

### 重み調整（Optuna）

```python
import optuna

def objective(trial):
    # ハイパーパラメータをOptunaが提案
    params = {
        'num_leaves': trial.suggest_int('num_leaves', 10, 50),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),
    }

    # モデル学習
    model = lgb.train(params, train_data, num_boost_round=100)

    # 評価（的中率や回収率など）
    predictions = model.predict(X_val)
    accuracy = calculate_accuracy(predictions, y_val)

    return accuracy  # 最大化したい指標

# 100通りの組み合わせを試す
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# 最適なパラメータ
best_params = study.best_params
```

### 説明可能性（SHAP）

```python
import shap

# SHAP値を計算
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_race[0])  # 1着予想馬

# 可視化
shap.waterfall_plot(shap.Explanation(
    values=shap_values,
    base_values=explainer.expected_value,
    data=X_race[0],
    feature_names=feature_names
))
```

**出力例**:
```
この馬を1着予想した理由:
+0.35: オッズが低い（2.8倍）
+0.22: 前走1着
+0.15: 内枠（3枠）
+0.08: 騎手勝率が高い
-0.05: やや休養明け（30日ぶり）
---
合計スコア: 0.75
```

### 終盤の作業（重み調整）

1. **特徴量の追加・削除**: 効果のない特徴量を削除、新しい特徴量を試す
2. **ハイパーパラメータチューニング**: Optunaで100〜1000通り試す
3. **評価指標の調整**: 的中率重視 or 回収率重視
4. **アンサンブル**: 複数モデルの予想を組み合わせ（LightGBM + XGBoost + CatBoost）

---

## 2.2 ルートB: ディープラーニング（ブラックボックス）

### 基本的な流れ

```
[1] データの埋め込み（Embedding）
  馬名、騎手名、厩舎名などを埋め込みベクトル化
  ↓
[2] ニューラルネットワークで学習
  大量のデータから自動的にパターン抽出
  ↓
[3] 予想生成
  各馬の勝率を予測し、上位3頭を出力
  ↓
[4] 精度評価
  ルートAと比較してどちらが良いか判定
```

### アーキテクチャ例

#### アプローチ1: TabNet（テーブルデータ向けDL）

```python
from pytorch_tabnet.tab_model import TabNetRegressor

model = TabNetRegressor(
    n_d=64,  # 決定次元
    n_a=64,  # 注意機構の次元
    n_steps=5,  # 推論ステップ数
    gamma=1.5,  # 特徴選択の強度
)

# 学習
model.fit(
    X_train, y_train,
    eval_set=[(X_val, y_val)],
    max_epochs=100,
)

# 予想
predictions = model.predict(X_race)
```

#### アプローチ2: Transformer（系列データ向け）

過去のレース履歴を系列データとして扱う:

```python
import torch
import torch.nn as nn

class RaceTransformer(nn.Module):
    def __init__(self, num_features, d_model=128, nhead=8):
        super().__init__()
        self.embedding = nn.Linear(num_features, d_model)
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(d_model, nhead),
            num_layers=6
        )
        self.fc = nn.Linear(d_model, 1)  # 勝率予測

    def forward(self, x):
        # x: [batch, seq_len, num_features]
        # 過去10走のデータを系列として入力
        x = self.embedding(x)
        x = self.transformer(x)
        x = x.mean(dim=1)  # 平均プーリング
        return self.fc(x)
```

#### アプローチ3: 埋め込み（Embedding）の活用

馬名・騎手名をベクトル化:

```python
class EmbeddingModel(nn.Module):
    def __init__(self, num_horses, num_jockeys, embedding_dim=32):
        super().__init__()
        self.horse_embedding = nn.Embedding(num_horses, embedding_dim)
        self.jockey_embedding = nn.Embedding(num_jockeys, embedding_dim)
        self.fc = nn.Linear(embedding_dim * 2 + other_features, 1)

    def forward(self, horse_id, jockey_id, other_features):
        horse_vec = self.horse_embedding(horse_id)
        jockey_vec = self.jockey_embedding(jockey_id)
        combined = torch.cat([horse_vec, jockey_vec, other_features], dim=1)
        return self.fc(combined)
```

### ブラックボックスの説明可能性

完全には説明できないが、部分的に可視化:

1. **Attention Weights**（Transformerの場合）: どの過去レースに注目したか
2. **Grad-CAM**: どの特徴量が重要だったか
3. **埋め込みベクトルの可視化**: 似た馬がクラスタになっているか

---

## 2.3 2つのルートの比較

### ルートA（ホワイトボックス）の利点

✅ **説明可能**: 「なぜこの予想か」がわかる
✅ **信頼性**: ユーザーに理屈を説明できる
✅ **デバッグしやすい**: 間違いの原因を特定可能
✅ **少ないデータでも動作**: 数千レースで十分

### ルートA の欠点

❌ **特徴量設計が必要**: 手動で特徴量を作る
❌ **複雑なパターン検出が苦手**: 非線形な関係の発見に限界

---

### ルートB（ブラックボックス）の利点

✅ **自動的にパターン発見**: 人間が気づかない関係も学習
✅ **大量データで強い**: データが増えるほど精度向上
✅ **特徴量エンジニアリング不要**: 生データを投げるだけ

### ルートB の欠点

❌ **説明不可能**: なぜその予想かわからない
❌ **過学習しやすい**: データが少ないと失敗
❌ **計算コスト高い**: GPUが必要な場合も
❌ **ユーザーの信頼を得にくい**: 「ブラックボックス」への不安

---

## 2.4 実装の優先順位

### フェーズ1: ルートAの基礎（現在〜3ヶ月）

1. 特徴量エンジニアリング
2. LightGBM実装
3. SHAP で説明可能性確保
4. 基本的なハイパーパラメータチューニング

**目標**: 的中率30%を目指す

### フェーズ2: ルートAの最適化（3〜6ヶ月）

5. 特徴量の追加（100個以上試す）
6. Optunaで徹底的にチューニング
7. アンサンブル学習（複数モデルの組み合わせ）
8. 回収率の最適化

**目標**: 的中率40%、回収率80%以上

### フェーズ3: ルートBの実験（6〜9ヶ月）

9. TabNet実装
10. Transformer実装
11. 埋め込みモデル実装
12. ルートAとの比較

**目標**: ルートAを超える精度を達成

### フェーズ4: 統合（9〜12ヶ月）

13. ルートAとBのアンサンブル
14. ユーザーに「ホワイトボックス予想」と「ブラックボックス予想」を両方提示
15. どちらが当たるか競争させる

---

## 2.5 最終的な統合: 「一本槍」+「参考予想」の2段構成

**コンセプトの維持**:
- サイト名「金沢ダート一本槍」は変えない
- **メイン予想（一本槍）= ホワイトボックスAI（ルートA）**
- 開発者自身が購入するのはこちら
- 大きく目立つ表示

**対決要素の追加**:
- **参考予想 = ディープラーニングAI（ルートB）**
- 小さめに表示、「実験的なAI予想」として紹介
- 毎週の的中率対決を記録

### UI表示イメージ

```
┌─────────────────────────────────────────┐
│  🎯 金沢ダート一本槍                     │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━      │
│                                          │
│         穂先 → 3番                       │
│         団子 → 7番                       │
│         団子 → 5番                       │
│         柄                               │
│                                          │
│  信頼度: ★★★★☆ 72%                    │
│  💰 開発者も購入                         │
│                                          │
│  ━━ 予想の根拠 ━━━━━━━━━━━━━━        │
│  ✓ 3番: オッズ2.8倍、内枠、前走1着      │
│  ✓ 7番: 騎手勝率22%、この距離得意       │
│  ✓ 5番: 連対率45%、馬場適性あり         │
│                                          │
│  [この予想の詳細を見る]                  │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│  🤖 参考: ディープラーニングAI予想       │
│  （実験的・説明不可能）  [折りたたむ]    │
├─────────────────────────────────────────┤
│  1着: 5番                                │
│  2着: 3番                                │
│  3着: 8番                                │
│  信頼度: 85%                             │
│                                          │
│  ⚠️ ブラックボックスAIのため、          │
│     なぜこの予想かは説明できません      │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│  📊 今シーズンの対決成績                 │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━      │
│  🎯 一本槍（ホワイトボックス）           │
│     34勝 / 85戦  勝率: 40.0%            │
│                                          │
│  🤖 ディープラーニング                   │
│     38勝 / 85戦  勝率: 44.7%            │
│                                          │
│  今週はDLが僅差でリード！                │
│  [詳細な対決記録を見る]                  │
└─────────────────────────────────────────┘
```

---

## 3. 時系列検証戦略

### 学習データとテストデータを分ける必要性

**ホワイトボックス（LightGBM）でもブラックボックス（DL）でも、必ず必要**:

❌ **間違ったやり方**:
```
全データ（2015-2025）で学習
  ↓
同じデータ（2015-2025）でテスト
  ↓
「的中率90%！」← これは過学習、実戦では使えない
```

✅ **正しいやり方**:
```
過去データ（2015-2024）で学習
  ↓
未来データ（2025）でテスト
  ↓
「的中率40%」← これが実戦で期待できる精度
```

### なぜ分ける必要があるのか？

**過学習（Overfitting）を防ぐため**:
- モデルが「訓練データを丸暗記」してしまう
- 学習データでは高精度だが、未知データでは全く当たらない
- **実戦で役に立たない予想システムになる**

---

## 3.1 時系列交差検証（Time Series Cross-Validation）

### 基本的な考え方

**「過去から見た未来」を複数回作る**

```
[検証1回目]
学習: 2015-2020 (6年分)
テスト: 2021 (1年分) ← 2020年時点では「未来」
  ↓
[検証2回目]
学習: 2015-2021 (7年分)
テスト: 2022 (1年分) ← 2021年時点では「未来」
  ↓
[検証3回目]
学習: 2015-2022 (8年分)
テスト: 2023 (1年分) ← 2022年時点では「未来」
  ↓
[検証4回目]
学習: 2015-2023 (9年分)
テスト: 2024 (1年分) ← 2023年時点では「未来」
  ↓
[検証5回目]
学習: 2015-2024 (10年分)
テスト: 2025 (1年分) ← 2024年時点では「未来」

平均精度: 5回の結果を平均 → これが実戦精度の予測値
```

### メリット

✅ **2026年を待たずに検証できる**
✅ **5回分のテスト結果から信頼性の高い精度推定**
✅ **「過去データで学習 → 未来データでテスト」を忠実に再現**
✅ **年度による偏りを平均化**

---

## 3.2 実装方法

### Pythonコード例（LightGBM）

```python
from sklearn.model_selection import TimeSeriesSplit
import lightgbm as lgb
import numpy as np

# データ準備（2015-2025の11年分）
years = np.arange(2015, 2026)
all_data = load_all_races()  # 全レースデータ

# 時系列分割（5回の検証）
tscv = TimeSeriesSplit(n_splits=5)

accuracies = []
for fold, (train_idx, test_idx) in enumerate(tscv.split(all_data)):
    print(f"[検証{fold+1}回目]")

    # 学習データとテストデータに分割
    train_data = all_data[train_idx]
    test_data = all_data[test_idx]

    train_year_range = (train_data['year'].min(), train_data['year'].max())
    test_year = test_data['year'].unique()[0]
    print(f"  学習: {train_year_range[0]}-{train_year_range[1]}")
    print(f"  テスト: {test_year}")

    # モデル学習
    model = lgb.LGBMRanker()
    model.fit(
        train_data[features],
        train_data['rank'],
        group=train_data['race_id']
    )

    # テストデータで予想
    predictions = model.predict(test_data[features])

    # 精度計算
    accuracy = calculate_accuracy(predictions, test_data)
    accuracies.append(accuracy)
    print(f"  的中率: {accuracy:.1%}\n")

# 平均精度
avg_accuracy = np.mean(accuracies)
std_accuracy = np.std(accuracies)
print(f"平均的中率: {avg_accuracy:.1%} ± {std_accuracy:.1%}")
print(f"これが実戦で期待できる精度です")
```

### 実行結果の例

```
[検証1回目]
  学習: 2015-2020
  テスト: 2021
  的中率: 38.2%

[検証2回目]
  学習: 2015-2021
  テスト: 2022
  的中率: 41.5%

[検証3回目]
  学習: 2015-2022
  テスト: 2023
  的中率: 39.8%

[検証4回目]
  学習: 2015-2023
  テスト: 2024
  的中率: 42.1%

[検証5回目]
  学習: 2015-2024
  テスト: 2025
  的中率: 40.3%

━━━━━━━━━━━━━━━━━━━━━━━
平均的中率: 40.4% ± 1.5%
これが実戦で期待できる精度です
━━━━━━━━━━━━━━━━━━━━━━━
```

---

## 3.3 ウォークフォワード分析

### 実戦シミュレーション

毎週モデルを再学習しながら検証:

```
週1: 2015/01-2020/12で学習 → 2021/01の第1週を予想
週2: 2015/01-2021/01で学習 → 2021/01の第2週を予想
週3: 2015/01-2021/01で学習 → 2021/01の第3週を予想
...
週N: 2015/01-2024/12で学習 → 2025/01の第1週を予想
```

**メリット**:
- より実戦に近い検証
- 最新データを常に反映

---

## 3.4 よくある間違い

### ❌ 間違い1: ランダム分割

```python
# これはダメ！
from sklearn.model_selection import train_test_split
train, test = train_test_split(all_data, test_size=0.2, random_state=42)
```

**問題点**:
- 時系列を無視している
- 「未来のデータで学習 → 過去を予想」になる
- 実戦では使えない精度が出る

### ❌ 間違い2: 全データで学習してテスト

```python
# これもダメ！
model.fit(all_data)
accuracy = model.score(all_data)  # 同じデータでテスト
```

**問題点**:
- 過学習を検出できない
- 虚偽の高精度

### ✅ 正解: 時系列を考慮した分割

```python
# 正しい方法
train = all_data[all_data['year'] <= 2023]
test = all_data[all_data['year'] == 2024]
model.fit(train)
accuracy = model.score(test)  # 未来データでテスト
```

---

## 3.5 2026年以降の運用

### 本番稼働後の検証

2026年になったら:

```
[2026年1月]
学習: 2015-2025 (11年分)
本番予想: 2026年1月第1週
  ↓ 結果確定後
実績記録: 的中 or 不的中
  ↓
[2026年1月第2週]
学習: 2015-2025 + 2026年1月第1週 (データ追加)
本番予想: 2026年1月第2週
  ↓
以降、毎週データを追加しながら学習
```

### 継続的な改善

```
定期的に再検証
  ↓
過去1年の的中率をモニタリング
  ↓
精度が落ちたら:
  - 特徴量の見直し
  - ハイパーパラメータ再調整
  - モデルアーキテクチャ変更
```

---

## 4. フロントエンドでの見せ方

### 検証結果ページ

```
┌─────────────────────────────────────────┐
│  🔬 予想精度の検証結果                   │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━      │
│                                          │
│  時系列交差検証（5回）の結果:            │
│                                          │
│  [2021年テスト] ███████████ 38.2%       │
│  [2022年テスト] █████████████ 41.5%     │
│  [2023年テスト] ████████████ 39.8%      │
│  [2024年テスト] ██████████████ 42.1%    │
│  [2025年テスト] ████████████ 40.3%      │
│                                          │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━      │
│  平均的中率: 40.4% ± 1.5%               │
│                                          │
│  ⚠️ 重要:                               │
│  この精度は「学習に使っていない未来      │
│  データ」で検証した結果です。            │
│  実戦でもこの精度が期待できます。        │
└─────────────────────────────────────────┘
```

---

## 5. コンテンツ化

### ルートAの説明記事

- 「AIはこうやって予想している」
- 「SHAP値で見る予想の根拠」
- 「特徴量ランキング: 最も効く要素は？」

### ルートBの説明記事

- 「ディープラーニングの実験」
- 「説明不可能だが高精度なAI」
- 「ブラックボックスvs説明可能AI、どちらが勝つ？」

### 対決企画

- 毎週「ルートA vs ルートB」の的中率を公開
- ユーザー投票: 「今週はどちらを信じる？」
- 長期的な勝敗記録

### 検証プロセスの公開

- 「なぜ2026年を待たずに精度を測れるのか」
- 時系列交差検証の仕組み
- 過学習とは何か
- 図解で分かりやすく説明

---

## まとめ

### 重要なポイント

1. **オッズを使う/使わないの実験**: AI独自の判断 vs 人間の集合知
2. **2つのルート**: ホワイトボックス（説明可能） vs ブラックボックス（高精度）
3. **時系列検証**: 2026年を待たなくても、過去データで実戦精度を測れる
4. **コンテンツ化**: すべての試行錯誤を公開し、透明性のある予想システムに

### 実装の流れ

```
[1] 全データ（2015-2025）を用意
  ↓
[2] 時系列交差検証（5回）
  各回: 過去データで学習 → 未来データでテスト
  ↓
[3] 平均精度を算出
  これが実戦精度の予測値
  ↓
[4] 最終モデルを構築
  全データ（2015-2025）で学習
  ↓
[5] 2026年以降の本番運用
  毎週データを追加して再学習
```

**完全に無駄のない開発プロセス。**
**一本槍のコンセプトを保ちつつ、対決で楽しさ倍増。**
