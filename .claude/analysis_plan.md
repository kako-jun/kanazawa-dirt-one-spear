# 金沢競馬データ分析計画

2015-2025年の11年分データ（約8,500レース）を活用した多角的分析のアイデア集

---

## 目次

1. [公正性検証・八百長検知](#1-公正性検証八百長検知)
2. [予想モデル構築](#2-予想モデル構築)
3. [統計分析・傾向把握](#3-統計分析傾向把握)
4. [可視化・ダッシュボード](#4-可視化ダッシュボード)
5. [異常検知・外れ値分析](#5-異常検知外れ値分析)
6. [時系列分析](#6-時系列分析)
7. [ネットワーク分析](#7-ネットワーク分析)
8. [経済分析](#8-経済分析)

---

## 1. 公正性検証・八百長検知

### 1.1 オッズと結果の整合性チェック

**分析手法:**
- オッズ（人気）と着順の相関係数を計算
- カイ二乗検定で独立性を検証
- 期待値との乖離度を計算

**異常パターン:**
- 1番人気の勝率が統計的に低すぎる
- 10番人気以下が不自然に高頻度で馬券圏内
- 特定の騎手・調教師の組み合わせでオッズと結果が乖離

**実装:**
```python
# オッズランク vs 着順のクロス集計
# 正常: 1番人気が最も勝率高い、2番人気が2番目...
# 異常: ランダム分布に近い、または逆相関
```

### 1.2 ベンフォードの法則

**理論:**
自然発生的な数値の先頭桁は特定の分布に従う（1が30%、2が18%...）
不正データは均等分布に近づく

**適用対象:**
- 三連単配当の先頭桁分布
- 単勝配当の先頭桁分布
- ゴールタイムの先頭桁分布

**実装:**
```python
import numpy as np
from scipy.stats import chisquare

# ベンフォード分布
benford = [0.301, 0.176, 0.125, 0.097, 0.079, 0.067, 0.058, 0.051, 0.046]

# 実際の配当先頭桁を集計
first_digits = [int(str(payout)[0]) for payout in payouts]
observed = np.bincount(first_digits)[1:10] / len(first_digits)

# カイ二乗検定
chi2, p_value = chisquare(observed, benford)
# p < 0.05 なら不自然
```

### 1.3 コーナー通過順の不自然なパターン

**着目点:**
- 最終コーナー1位 → ゴール5位以下（急失速）
- 3コーナーまで最下位 → 4コーナーで急上昇 → 1位（不自然な追い込み）
- 同じ馬が「勝つレース」と「負けるレース」で走り方が全く異なる

**実装:**
```python
# 4コーナー位置 → ゴール順位の変化量を計算
# 異常値検出（±5位以上の変動）
# 特定の馬・騎手で異常頻度が高いか
```

### 1.4 高配当レースの頻度分析

**理論:**
三連単の期待配当分布は対数正規分布に従うはず
不正がある場合、特定範囲に偏る

**分析:**
- 10万円超の超高配当レースの発生頻度
- ポアソン分布でモデル化し、実測値と比較
- 特定の月・曜日に集中していないか

### 1.5 騎手・調教師のパフォーマンス異常

**着目点:**
- 同じ騎手が同じ馬で「勝率100%の期間」と「勝率0%の期間」
- 特定の調教師の馬が「勝つとき」のオッズパターン
- 騎手A×調教師Bの組み合わせでのみ異常勝率

**実装:**
```python
# グループ化: (騎手, 調教師, 馬) の組み合わせごとに勝率計算
# 期待値（全体勝率）との差分をZ検定
# p < 0.001 で異常判定
```

---

## 2. 予想モデル構築

### 予想の観点分類

**データの時間的価値を考慮した3つの観点:**

1. **馬による予想** (データの鮮度: 重要)
   - 馬の寿命: 競走馬は2-10歳程度が現役
   - **有効データ期間: 直近2-3年が中心**
   - 10年前のデータ: ほぼ無効（その馬はもう引退）
   - 活用方法: 現役馬の直近成績、調子の波

2. **騎手による予想** (データの鮮度: 中程度)
   - 騎手のキャリア: 10-30年程度
   - **有効データ期間: 5-10年**
   - 10年前のデータ: 参考になるが、加齢・技術変化を考慮
   - 活用方法: 騎手の得意距離、馬場、戦法

3. **場による予想** (データの鮮度: 低い、長期利用可)
   - 競馬場の特性: ほぼ不変
   - **有効データ期間: 10年以上**
   - 10年前のデータ: 有効（コース形状、距離、枠番有利など）
   - 活用方法: 枠番別勝率、距離別傾向、馬場状態の影響

**データ活用戦略:**
```python
# 馬の分析: 直近2年のデータのみ使用
horse_recent_data = races[races['date'] >= '2023-01-01']

# 騎手の分析: 直近5年のデータ使用
jockey_data = races[races['date'] >= '2020-01-01']

# 場の分析: 全期間（2015-2025）のデータ使用
track_data = races  # 全データ
```

### 2.1 LightGBM Rankerモデル

**特徴量設計:**

**基本特徴量:**
- 馬番、枠番
- 騎手（One-Hot or Target Encoding）
- 調教師（One-Hot or Target Encoding）
- 馬齢、性別
- 負担重量
- オッズ（人気順位）

**過去成績特徴量:**
- 過去5走の平均着順
- 過去5走の平均上がり3F
- 直近勝率（1ヶ月以内）
- 同距離での成績
- 同馬場状態での成績

**コース特性:**
- 距離（1200, 1400, 1500, 1700...）
- 馬場状態（良、稍重、重、不良）
- 天候（晴、曇、雨、雪）
- 周回方向（左、右）

**位置取り特徴量:**
- 過去レースの1-4コーナー平均位置
- 「逃げ」「先行」「差し」「追込」の戦法分類

**交互作用特徴量:**
- 騎手×馬場状態
- 距離×馬齢
- オッズ×過去勝率

**ターゲット:**
- 着順（1位=1, 2位=2, ...）をRankingタスクとして学習

**評価指標:**
- NDCG@3（上位3頭を正しく予測できたか）
- 的中率（1-3位を当てる）
- 回収率（予想通りに購入した場合の収支）

### 2.2 ニューラルネットワークモデル

**アーキテクチャ:**
```python
# Entity Embedding for categorical features
# 馬ID, 騎手ID, 調教師IDを低次元ベクトルに変換

# 多層パーセプトロン
Input → [Embedding] → Dense(128) → Dropout(0.3) → Dense(64) → Dense(1)

# 出力: 勝率予測（0-1の確率）
```

**損失関数:**
- Binary Cross Entropy（1着か否か）
- または Ranking Loss（pairwise learning）

### 2.3 アンサンブル

- LightGBM + NN + XGBoost の予測値を加重平均
- スタッキング（メタ学習器で最終予測）

### 2.4 説明可能性分析

**SHAP値で特徴量重要度を可視化:**
- 「このレースで7番が勝つと予測した理由」を説明
- 騎手、馬場、過去成績のどれが効いたか

---

## 2.5 馬のタイプ分類による予測

**問題意識:**
10年前の馬のデータは直接使えないが、「似たタイプの馬」という概念で活用可能

**実装アプローチ:**

**ステップ1: 馬のタイプ分類**
```python
# クラスタリングで馬をタイプ分け
from sklearn.cluster import KMeans

# 特徴量: 体重、距離適性、脚質、馬場適性など
horse_features = [
    'avg_distance',        # 平均出走距離
    'running_style',       # 脚質（逃げ=1, 先行=2, 差し=3, 追込=4）
    'track_preference',    # 馬場適性（良馬場での勝率）
    'age_at_peak',         # ピーク年齢
    'weight_avg',          # 平均体重
]

# K-meansで5つのタイプに分類
# タイプ例: 「スプリンター型」「マイラー型」「ステイヤー型」など
kmeans = KMeans(n_clusters=5)
horse_types = kmeans.fit_predict(horse_data[horse_features])
```

**ステップ2: タイプ別の傾向を学習**
```python
# 過去10年間の「タイプ1」の馬の成績を集計
type1_horses = historical_horses[historical_horses['type'] == 1]

# タイプ1の特徴:
# - 1400m以下で勝率高い
# - 逃げ・先行が多い
# - 良馬場で強い

# 現在の「タイプ1」の馬に、過去のタイプ1のパターンを適用
```

**ステップ3: 類似馬検索**
```python
# コサイン類似度で似た馬を検索
from sklearn.metrics.pairwise import cosine_similarity

# 現在の馬Aに似た過去の馬を検索
similar_horses = find_similar_horses(horse_A, historical_data, top_k=10)

# 類似馬の過去成績から傾向を学習
# 「この馬は過去の○○に似ている → ○○は1500mで好走 → この馬も1500mが狙い目」
```

**活用例:**
- 新馬（デビュー馬）の予想: 似た体格・血統の過去馬から推測
- 距離変更時の予想: 似た馬が距離変更でどうだったか
- 馬場変化への対応: 似た馬が重馬場でどうだったか

## 3. 統計分析・傾向把握

### 3.0 競馬オカルトの科学的検証

**目的:**
競馬界で語り継がれる「オカルト」が統計的に本当か検証する

**検証項目:**

**1. 「内枠有利・外枠不利」**
```python
# 仮説: 1-2枠が有利、7-8枠が不利
# 検証: 枠番別勝率をカイ二乗検定
# 結果: 距離別・馬場状態別に層別分析
```
- 期待: 短距離は内枠有利、長距離は外枠有利
- 統計的有意性を確認（p < 0.05）

**2. 「雨の日は荒れる」**
```python
# 仮説: 雨天時は人気薄が好走し、高配当が出やすい
# 検証: 天候別の配当分布を比較
# 晴れ: 平均配当3,500円
# 雨: 平均配当4,800円
# t検定で有意差を検証
```

**3. 「連続出走は疲労で負けやすい」**
```python
# 仮説: 連続出走（中1週以下）は成績が落ちる
# 検証: 休養週数別の勝率比較
# 中1週: 勝率8.2%
# 中2週: 勝率10.5%
# 中3週以上: 勝率9.8%
```

**4. 「人気の盲点（4-6番人気が狙い目）」**
```python
# 仮説: 1-3番人気はオッズが低く旨味がない
#       7番人気以下は実力不足
#       4-6番人気が期待値高い
# 検証: 人気別の回収率計算
```

**5. 「重賞明けは負けやすい」**
```python
# 仮説: 重賞（大きなレース）の直後は調整不足で負ける
# 検証: 前走レースグレード別の今走成績
```

**6. 「大外一気」は都市伝説？**
```python
# 仮説: 最後方から一気に差すパターンは実は稀
# 検証: 4コーナー最下位からの1着率を計算
# 期待: 映画的だが実際は数%程度
```

**7. 「ゴール前で差されやすい馬」**
```python
# 仮説: 特定の馬は「あと一歩で届かない」パターンが多い
# 検証: 4コーナー1位 → ゴール2-3着の頻度
# 馬ごとに集計し、「勝ち切れない馬」をリストアップ
```

**8. 「満月の日は荒れる」（疑似科学）**
```python
# 仮説: 満月の日は配当が高くなる（疑似科学的）
# 検証: 月齢データと配当の相関分析
# 期待: おそらく相関なし（p > 0.05）→ オカルトを否定
```

**9. 「ベテラン騎手は大舞台に強い」**
```python
# 仮説: 重賞レースでは経験豊富な騎手が有利
# 検証: 騎手経験年数 × レースグレードの交互作用
```

**10. 「追い込み馬は展開次第」**
```python
# 仮説: 前が速いペースだと追い込み有利、遅いと不利
# 検証: 1-2コーナーの平均ペース × 脚質別の勝率
# ※ペースデータがあれば
```

**オカルト検証レポート:**
- 各検証結果を「科学的根拠あり」「オカルト（根拠なし）」に分類
- ブログ記事化: 「金沢競馬10年分のデータで競馬オカルトを検証してみた」
- 面白い発見を可視化してSNSで拡散

**実装コード例:**
```python
def verify_myth(hypothesis_name, data, test_func):
    """オカルト検証の統一インターフェース"""
    result = test_func(data)
    p_value = result['p_value']

    if p_value < 0.05:
        print(f"✅ {hypothesis_name}: 統計的に有意（根拠あり）")
    else:
        print(f"❌ {hypothesis_name}: 統計的に有意でない（オカルト）")

    return result

# 使用例
verify_myth(
    "内枠有利説",
    race_data,
    lambda df: chi2_test(df['gate'], df['result'])
)
```



### 3.1 騎手ランキング

**指標:**
- 勝率、連対率、複勝率
- 平均着順
- 回収率（単勝、三連単）
- 馬場状態別成績
- 距離別成績

**可視化:**
- レーダーチャート（総合力）
- ヒートマップ（騎手×馬場状態）

### 3.2 馬場状態の影響

**分析:**
- 「良」「稍重」「重」「不良」での勝率変化
- 馬場悪化時に強い騎手/馬
- 雨天時の配当傾向（荒れやすいか）

### 3.3 枠番有利・不利

**分析:**
- 1-8枠の勝率比較
- 距離別の有利枠（1400mは内枠有利、1700mは外枠有利、など）
- カイ二乗検定で統計的有意性を検証

### 3.4 人気と配当の関係

**分析:**
- 1番人気の勝率（他競馬場との比較）
- 人気薄（10番人気以下）の複勝率
- 三連単の「堅い決着」「大波乱」の比率

### 3.5 季節・曜日の傾向

**分析:**
- 春/夏/秋/冬の配当平均
- 土日vs平日のレース質
- ゴールデンウィーク、お盆などイベント時の傾向

---

## 4. 可視化・ダッシュボード

### 4.1 Streamlitダッシュボード

**ページ構成:**

**トップページ:**
- 総レース数、総配当額
- 最高配当レースのハイライト
- 直近の予想的中率

**騎手分析:**
- 騎手選択 → 成績サマリー
- 勝率推移グラフ（時系列）
- 得意距離・馬場のヒートマップ

**レース検索:**
- 日付・レース番号で検索
- 出馬表、結果、配当を表示
- コーナー通過順の可視化（折れ線グラフ）

**予想シミュレーション:**
- 過去レースを選択
- モデルの予想結果と実際の結果を比較
- 「もし予想通り買っていたら」の収支計算

### 4.2 コーナー通過順のアニメーション

**実装:**
- Plotly/Matplotlibで各馬の位置変化をアニメーション
- 1コーナー → 2コーナー → 3コーナー → 4コーナー → ゴール
- 逆転劇、大逃げ、追い込み成功などを視覚化

### 4.3 配当分布の可視化

**グラフ:**
- ヒストグラム（対数スケール）
- 箱ひげ図（賭式別）
- バイオリンプロット（年度別）

---

## 5. 異常検知・外れ値分析

### 5.1 Isolation Forest

**適用:**
- 全レースを多次元空間にプロット（配当、人気、コーナー順位変化など）
- 外れ値を検出 → 異常レースとしてマーク

### 5.2 LOF（Local Outlier Factor）

**適用:**
- 騎手のパフォーマンスベクトル（勝率、平均着順、回収率）
- 他の騎手と大きく異なる行動パターンを検出

### 5.3 時系列異常検知

**手法:**
- Prophet（Facebook）で配当額の時系列予測
- 予測誤差が大きい日を「異常日」として抽出

---

## 6. 時系列分析

### 6.1 勝率の推移

**分析:**
- 特定騎手の勝率推移（移動平均）
- 「好調期」「不調期」の検出
- 調子の波のサイクル（周期性分析）

### 6.2 配当額のトレンド

**分析:**
- 三連単平均配当の年次推移
- 「荒れる時期」「堅い時期」の季節性
- ARIMA/SARIMAモデルで将来予測

### 6.3 オッズ変動パターン

**分析（追加データが必要）:**
- もし時系列オッズが取れれば、「直前人気急上昇」などを検出

---

## 7. ネットワーク分析

### 7.1 騎手-調教師ネットワーク

**可視化:**
- ノード: 騎手、調教師
- エッジ: 共同回数（重み）
- コミュニティ検出: 特定グループの存在

### 7.2 馬-騎手の相性ネットワーク

**分析:**
- 特定の馬×騎手の組み合わせで勝率が高い
- NetworkXでグラフ構築 → 中心性指標

---

## 8. 経済分析

### 8.1 回収率シミュレーション

**戦略:**
- 全レース三連単1点買い → 回収率XX%
- 人気薄狙い（5-10番人気の組み合わせ）→ 回収率YY%
- モデル予想上位3頭のBOX買い → 回収率ZZ%

**比較:**
- ランダム購入
- 人気順購入
- AI予想購入

### 8.2 期待値分析

**理論:**
- 各馬券の期待値 = 払戻金 × 的中確率 - 購入額
- 期待値プラスの馬券だけを購入したら？

### 8.3 ケリー基準による賭け金最適化

**理論:**
```
f* = (bp - q) / b
f*: 賭け金比率
b: オッズ-1
p: 的中確率
q: 外れ確率
```

**実装:**
- モデルで的中確率を推定
- オッズと比較して「割の良い馬券」を検出
- 最適賭け金を計算

---

## 9. 実装の優先順位

### フェーズ1: データ整備（現在進行中）
- [x] スクレイピング
- [ ] データクレンジング
- [ ] データベース整備

### フェーズ2: 基礎分析
1. 記述統計（勝率、配当分布）
2. 騎手ランキング
3. 枠番・馬場状態分析
4. 可視化ダッシュボード構築

### フェーズ3: 公正性検証
1. ベンフォード検証
2. オッズ-結果整合性チェック
3. 異常レース検出
4. レポート作成

### フェーズ4: 予想モデル
1. LightGBM Ranker実装
2. 特徴量エンジニアリング
3. モデル評価
4. 実運用シミュレーション

### フェーズ5: 高度な分析
1. ニューラルネット
2. アンサンブル
3. ネットワーク分析
4. 時系列予測

---

## 10. 必要なライブラリ

```python
# データ処理
pandas
numpy
sqlalchemy

# 機械学習
scikit-learn
lightgbm
xgboost
tensorflow / pytorch  # NN用

# 統計
scipy
statsmodels

# 可視化
matplotlib
seaborn
plotly
streamlit

# 異常検知
pyod

# ネットワーク
networkx

# 時系列
prophet
```

---

## 11. アウトプット案

### ブログ記事
- 「金沢競馬11年分のデータで見えた騎手の実力」
- 「ベンフォードの法則で競馬の公正性を検証してみた」
- 「AIは競馬で勝てるのか？機械学習モデルの実力」

### GitHub公開
- オープンソース化（個人情報を除く）
- Jupyter Notebookでの分析例
- Streamlitダッシュボードのデモ

### 論文・レポート
- 「地方競馬における統計的公正性検証」
- 「機械学習を用いた競馬予想モデルの構築と評価」

---

## 12. 倫理的配慮

- **ギャンブル依存への配慮**: 「必ず当たる」などの過剰な表現を避ける
- **個人攻撃の回避**: 特定の騎手・調教師を名指しで批判しない
- **データの透明性**: 分析手法を公開し、再現可能にする
- **法的遵守**: 競馬法、著作権法に抵触しない範囲での利用

---

## まとめ

11年分、8,500レースのデータは宝の山です。
統計、機械学習、可視化、異常検知など、あらゆる分析手法を試せます。

最も重要なのは「なぜこの分析をするのか」という目的意識。
- 公正性の検証
- 予想精度の向上
- 競馬の楽しみ方の発見

データ分析を通じて、金沢競馬の面白さを再発見しましょう！
